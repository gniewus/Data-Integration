{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The imdb shape: 6407 x 13\n",
      "The rt shape: 6407 x 13\n"
     ]
    }
   ],
   "source": [
    "im= pd.read_csv(\"./imdb.csv\");\n",
    "rt= pd.read_csv(\"./rotten_tomatoes.csv\");\n",
    "print('The imdb shape: %d x %d' % im.shape)\n",
    "print('The rt shape: %d x %d' % im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split words in the n-grams\n",
    "def ngrams(string, n=2):\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "\n",
    "    \n",
    "#compute dice for array or string \n",
    "def dice_coefficient(a, b,n=2):\n",
    "    \"\"\"dice coefficient 2nt/na + nb.\"\"\"\n",
    "    \n",
    "    #For comparing strings \n",
    "    if isinstance(a,str) & isinstance(b,str):\n",
    "        a = ngrams(a,n)\n",
    "        b = ngrams(b,n)\n",
    "        \n",
    "    #For comparing lists  \n",
    "    a_bigrams = set(a)\n",
    "    b_bigrams = set(b)\n",
    "    overlap = len(a_bigrams & b_bigrams)\n",
    "    return overlap * 2.0/(len(a_bigrams) + len(b_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_coefficient(\"Name\",\"Nameee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Director</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Language</th>\n",
       "      <th>Country</th>\n",
       "      <th>Duration</th>\n",
       "      <th>RatingValue</th>\n",
       "      <th>RatingCount</th>\n",
       "      <th>ReviewCount</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Filming Locations</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Name, Year, Release Date, Director, Creator, Actors, Cast, Language, Country, Duration, RatingValue, RatingCount, ReviewCount, Genre, Filming Locations, Description]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>YearRange</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Director</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Duration</th>\n",
       "      <th>RatingValue</th>\n",
       "      <th>ContentRating</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Url</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Name, YearRange, ReleaseDate, Director, Creator, Cast, Duration, RatingValue, ContentRating, Genre, Url, Description]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.head(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## General Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ibmd : RottenTomatoes\n",
    "GT = {\n",
    "      \"Name\":\"Name\",\n",
    "      \"ReleaseDate\":\"Release Date\",\n",
    "      \"RatingValue\":\"RatingValue\",\n",
    "      \"Director\":\"Director\",\n",
    "      \"Creator\":\"Creator\",\n",
    "      \"YearRange\":\"Year\",\n",
    "      \"Genre\":\"Genre\",\n",
    "      \"Duration\":\"Duration\",\n",
    "      \"Cast\":\"Cast\",\n",
    "        \"Description\":\"Description\"\n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Label Based Mapping\n",
    "\n",
    "Here, we want to find the correspondences between the columns from the two datasets\n",
    "with the help of only schema headers.\n",
    "1. Provide an algorithm. Specify the input, output, similarity function, and time\n",
    "complexity.\n",
    "2. Implement the algorithm and report the results. Is there any parameter that affects\n",
    "the results?\n",
    "3. What is the upsides and downsides of this method? When does it work and when\n",
    "not?\n",
    "\n",
    "### Solution: \n",
    "*Dice-distance based algoritgm*\n",
    "\n",
    "**get_mapping** is the main function of the algortihm. It takes two data tables (padans DataFrame) and a treshold value for the N-Grams computed using Dice Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mapping(table_a,table_b,treshold=0.5,n=2):\n",
    "    #print(\"Treshold: {}, {}-grams\".format(treshold,n))\n",
    "    A =[ str(a) for a in table_a.columns]\n",
    "    B =[ str(b) for b in table_b.columns]\n",
    "    #HardCoded skiping IDs\n",
    "    A.remove('Id')\n",
    "    B.remove('Id')\n",
    "    #List of arrays containg header label and it's Ngram represatantion,\n",
    "    rt_cl = [[ngrams(cl,n),cl]for cl in A]\n",
    "    im_cl = [[ngrams(cl,n),cl] for cl in B]\n",
    "    df = pd.DataFrame(columns=[\"tab_a_entry\",\"tab_b_entry\",\"coeff\"])\n",
    "    for r,r_ in rt_cl:\n",
    "        for i,i_ in im_cl:\n",
    "            dc = dice_coefficient(r,i)\n",
    "\n",
    "            if (dc >= treshold ) or (r_ in i_):\n",
    "                df = df.append(pd.Series([r_,i_,dc],index=[\"tab_a_entry\",\"tab_b_entry\",\"coeff\"]),ignore_index=True)\n",
    "\n",
    "    df = df.groupby(['tab_a_entry'], sort=True)['tab_a_entry','tab_b_entry','coeff'].max()\n",
    "    return dict(zip(df[\"tab_a_entry\"],df['tab_b_entry']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_recall(mapping):\n",
    "    total_found =len(mapping.items())\n",
    "    #print(\"Recall {}\".format(float(total_found/len(GT.items()))))\n",
    "    return float(total_found/len(GT.items()))\n",
    "                 \n",
    "def compute_precision(mapping):\n",
    "    precision = set(mapping.items()) & set(GT.items())\n",
    "    true_matches = len(precision)\n",
    "    total_found =len(mapping.items())\n",
    "    #print(\"Precision {}\".format(float(true_matches/total_found)))\n",
    "    return float(true_matches/total_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def what_is_missing_or_wrong(mapping):\n",
    "    #Helper method\n",
    "    def _removekey(d, key):\n",
    "        r = dict(d)\n",
    "        del r[key]\n",
    "        return r\n",
    "    \n",
    "    missing = list()\n",
    "    for x in GT.items():\n",
    "        try:\n",
    "            mapping= _removekey(mapping,x[0])\n",
    "        except KeyError as e:\n",
    "            #print(\"Missing : \"+x[0])\n",
    "            missing.append(x)\n",
    "                               \n",
    "    return missing, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_algo(tableA,tableB,to_csv=False):\n",
    "    treshold_test_axis = np.arange(0.001, 1, .02);\n",
    "    ngram_test_axis = np.arange(1,5)\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"treshold\",\"ngrams\",\"precision\",\"recall\",\"total_matches\",\"uniqie_matches\"])\n",
    "    for t in treshold_test_axis:\n",
    "        for n in ngram_test_axis:\n",
    "            print(t,n)\n",
    "            mp =get_mapping(tableA,tableB,t,n)\n",
    "            prec =compute_precision(mp)\n",
    "            recall= compute_recall(mp)\n",
    "            unique = set(mp.items())\n",
    "            df = df.append(pd.Series([t,n,prec,recall,len(mp.items()),len(unique)],index=[\"treshold\",\"ngrams\",\"precision\",\"recall\",\"total_matches\",\"uniqie_matches\"]),ignore_index=True)\n",
    "    df['precision_normalised']=(df['precision'] - df['precision'].mean()) / (df['precision'].max() - df['precision'].min())\n",
    "    df['recall_normalised']=  (df['recall'] - df['recall'].mean()) / (df['recall'].max() - df['recall'].min())\n",
    "    if to_csv:\n",
    "        df.to_csv('test.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.001, 1)\n",
      "(0.001, 2)\n",
      "(0.001, 3)\n",
      "(0.001, 4)\n",
      "(0.031, 1)\n",
      "(0.031, 2)\n",
      "(0.031, 3)\n",
      "(0.031, 4)\n",
      "(0.060999999999999999, 1)\n",
      "(0.060999999999999999, 2)\n",
      "(0.060999999999999999, 3)\n",
      "(0.060999999999999999, 4)\n",
      "(0.090999999999999998, 1)\n",
      "(0.090999999999999998, 2)\n",
      "(0.090999999999999998, 3)\n",
      "(0.090999999999999998, 4)\n",
      "(0.121, 1)\n",
      "(0.121, 2)\n",
      "(0.121, 3)\n",
      "(0.121, 4)\n",
      "(0.151, 1)\n",
      "(0.151, 2)\n",
      "(0.151, 3)\n",
      "(0.151, 4)\n",
      "(0.18099999999999999, 1)\n",
      "(0.18099999999999999, 2)\n",
      "(0.18099999999999999, 3)\n",
      "(0.18099999999999999, 4)\n",
      "(0.21099999999999999, 1)\n",
      "(0.21099999999999999, 2)\n",
      "(0.21099999999999999, 3)\n",
      "(0.21099999999999999, 4)\n",
      "(0.24099999999999999, 1)\n",
      "(0.24099999999999999, 2)\n",
      "(0.24099999999999999, 3)\n",
      "(0.24099999999999999, 4)\n",
      "(0.27100000000000002, 1)\n",
      "(0.27100000000000002, 2)\n",
      "(0.27100000000000002, 3)\n",
      "(0.27100000000000002, 4)\n",
      "(0.30099999999999999, 1)\n",
      "(0.30099999999999999, 2)\n",
      "(0.30099999999999999, 3)\n",
      "(0.30099999999999999, 4)\n",
      "(0.33099999999999996, 1)\n",
      "(0.33099999999999996, 2)\n",
      "(0.33099999999999996, 3)\n",
      "(0.33099999999999996, 4)\n",
      "(0.36099999999999999, 1)\n",
      "(0.36099999999999999, 2)\n",
      "(0.36099999999999999, 3)\n",
      "(0.36099999999999999, 4)\n",
      "(0.39100000000000001, 1)\n",
      "(0.39100000000000001, 2)\n",
      "(0.39100000000000001, 3)\n",
      "(0.39100000000000001, 4)\n",
      "(0.42099999999999999, 1)\n",
      "(0.42099999999999999, 2)\n",
      "(0.42099999999999999, 3)\n",
      "(0.42099999999999999, 4)\n",
      "(0.45099999999999996, 1)\n",
      "(0.45099999999999996, 2)\n",
      "(0.45099999999999996, 3)\n",
      "(0.45099999999999996, 4)\n",
      "(0.48099999999999998, 1)\n",
      "(0.48099999999999998, 2)\n",
      "(0.48099999999999998, 3)\n",
      "(0.48099999999999998, 4)\n",
      "(0.51100000000000001, 1)\n",
      "(0.51100000000000001, 2)\n",
      "(0.51100000000000001, 3)\n",
      "(0.51100000000000001, 4)\n",
      "(0.54100000000000004, 1)\n",
      "(0.54100000000000004, 2)\n",
      "(0.54100000000000004, 3)\n",
      "(0.54100000000000004, 4)\n",
      "(0.57099999999999995, 1)\n",
      "(0.57099999999999995, 2)\n",
      "(0.57099999999999995, 3)\n",
      "(0.57099999999999995, 4)\n",
      "(0.60099999999999998, 1)\n",
      "(0.60099999999999998, 2)\n",
      "(0.60099999999999998, 3)\n",
      "(0.60099999999999998, 4)\n",
      "(0.63100000000000001, 1)\n",
      "(0.63100000000000001, 2)\n",
      "(0.63100000000000001, 3)\n",
      "(0.63100000000000001, 4)\n",
      "(0.66099999999999992, 1)\n",
      "(0.66099999999999992, 2)\n",
      "(0.66099999999999992, 3)\n",
      "(0.66099999999999992, 4)\n",
      "(0.69099999999999995, 1)\n",
      "(0.69099999999999995, 2)\n",
      "(0.69099999999999995, 3)\n",
      "(0.69099999999999995, 4)\n",
      "(0.72099999999999997, 1)\n",
      "(0.72099999999999997, 2)\n",
      "(0.72099999999999997, 3)\n",
      "(0.72099999999999997, 4)\n",
      "(0.751, 1)\n",
      "(0.751, 2)\n",
      "(0.751, 3)\n",
      "(0.751, 4)\n",
      "(0.78100000000000003, 1)\n",
      "(0.78100000000000003, 2)\n",
      "(0.78100000000000003, 3)\n",
      "(0.78100000000000003, 4)\n",
      "(0.81099999999999994, 1)\n",
      "(0.81099999999999994, 2)\n",
      "(0.81099999999999994, 3)\n",
      "(0.81099999999999994, 4)\n",
      "(0.84099999999999997, 1)\n",
      "(0.84099999999999997, 2)\n",
      "(0.84099999999999997, 3)\n",
      "(0.84099999999999997, 4)\n",
      "(0.871, 1)\n",
      "(0.871, 2)\n",
      "(0.871, 3)\n",
      "(0.871, 4)\n",
      "(0.90099999999999991, 1)\n",
      "(0.90099999999999991, 2)\n",
      "(0.90099999999999991, 3)\n",
      "(0.90099999999999991, 4)\n",
      "(0.93099999999999994, 1)\n",
      "(0.93099999999999994, 2)\n",
      "(0.93099999999999994, 3)\n",
      "(0.93099999999999994, 4)\n",
      "(0.96099999999999997, 1)\n",
      "(0.96099999999999997, 2)\n",
      "(0.96099999999999997, 3)\n",
      "(0.96099999999999997, 4)\n",
      "(0.99099999999999999, 1)\n",
      "(0.99099999999999999, 2)\n",
      "(0.99099999999999999, 3)\n",
      "(0.99099999999999999, 4)\n"
     ]
    }
   ],
   "source": [
    "test_ = test_algo(im,rt,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 2\n",
    "#### Instance-Based Schema Matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im= pd.read_csv(\"./imdb.csv\");\n",
    "rt= pd.read_csv(\"./rotten_tomatoes.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_cl=im.columns.values\n",
    "rt_cl=rt.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Duplicate():\n",
    "    def __init__(self,src,target):\n",
    "        self.sCol = src.columns.values\n",
    "        self.tCol = target.columns.values\n",
    "        self.src=src.dropna()\n",
    "        self.target=target.dropna()\n",
    "        self.duplicates= list()\n",
    "        \n",
    "    def find_duplicate(self):\n",
    "        example_tp =self.src.sample(1).values;\n",
    "        for col in self.tCol:\n",
    "            if !self.duplicates:\n",
    "                self.target[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}